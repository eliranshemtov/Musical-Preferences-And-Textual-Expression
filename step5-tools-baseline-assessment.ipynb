{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Assessment\n",
    "\n",
    "After applying the few \"state of the art\" tools and gathering their predictions on golden-standard datasets (essays & myPersonality), We'll assess result's accuracy and correlation to the datasets' true labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize The Results\n",
    "\n",
    "Combine predictions from various tools and assess\n",
    "\n",
    "First, we manually combined the results to speadsheets, against the true labels.\n",
    "The assessment spreadsheets are available here:\n",
    "\n",
    "- [Essays dataset](https://github.com/eliranshemtov/Musical-Preferences-And-Textual-Expression/blob/main/analysis/tools-baseline/essays-combined-predictions.xlsx)\n",
    "- [MyPersonality dataset](https://github.com/eliranshemtov/Musical-Preferences-And-Textual-Expression/blob/main/analysis/tools-baseline/myPersonality-combined-predictions.xlsx)\n",
    "- [MyPersonality concatenated dataset](https://github.com/eliranshemtov/Musical-Preferences-And-Textual-Expression/blob/main/analysis/tools-baseline/myPersonality-concatenated-combined-predictions.xlsx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pearson correlation coefficient\n",
    "\n",
    "is a measure of the strength and direction of the linear relationship between two quantitative variables. It is a number between -1 and 1 that measures the strength and direction of the relationship between two variables. The Pearson correlation coefficient is the most common way of measuring a linear correlation. It is a descriptive statistic, meaning that it summarizes the characteristics of a dataset. Specifically, it describes the strength and direction of the linear relationship between two quantitative variables. The formula for Pearson's correlation coefficient is the covariance of the two variables divided by the product of their standard deviations. The Pearson correlation coefficient is also an inferential statistic, meaning that it can be used to test statistical hypotheses.\n",
    "\n",
    "I am going to calculate the Pearson correlation coefficient for every type of prediction of the Big Five traits, by every one of the tools I used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=-0.8285038835884277, pvalue=0.021280260007523352)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Example:\n",
    "x, y = [1, 2, 3, 4, 5, 6, 7], [10, 9, 2.5, 6, 4, 3, 2]\n",
    "res = stats.pearsonr(x, y)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperations & Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_keys = [\"cEXT\", \"cNEU\", \"cAGR\", \"cCON\", \"cOPN\"]\n",
    "tool1_keys = [\n",
    "    \"pred_sEXT_normalized\",\n",
    "    \"pred_sNEU_normalized\",\n",
    "    \"pred_sAGR_normalized\",\n",
    "    \"pred_sCON_normalized\",\n",
    "    \"pred_sOPN_normalized\",\n",
    "]\n",
    "tool3_keys = [\n",
    "    \"BIG5_Extraversion\",\n",
    "    \"BIG5_Neuroticism\",\n",
    "    \"BIG5_Agreeableness\",\n",
    "    \"BIG5_Conscientiousness\",\n",
    "    \"BIG5_Openness\",\n",
    "]\n",
    "tool4_keys = [\n",
    "    \"cEXT_prediction\",\n",
    "    \"cNEU_prediction\",\n",
    "    \"cAGR_prediction\",\n",
    "    \"cCON_prediction\",\n",
    "    \"cOPN_prediction\",\n",
    "]\n",
    "\n",
    "true_and_tool1_labels = {true_labels_keys[i]: tool1_keys[i] for i in range(5)}\n",
    "true_and_tool3_labels = {true_labels_keys[i]: tool3_keys[i] for i in range(5)}\n",
    "true_and_tool4_labels = {true_labels_keys[i]: tool4_keys[i] for i in range(5)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "\n",
    "Every tool's data had to be normalized in a certain way to be used for calculations.\n",
    "\n",
    "- The True-Labels are loaded and transformed from \"y\"/\"n\" format to 0/1 format.\n",
    "- Tool #4's data is simply converted to int\n",
    "- Tool #3's data is thresholded on 0.5 (>= 0.5 is 1, otherwise 0)\n",
    "- Tool #1's data had to be re-noramalized using the following method in addition to 0.5 threshold. Details are in the method's docstring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_normalize_tool_1(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    The original normalization logic done by the actual tool is as follows and does not yield meaningful results because the prediction for OPN and NEU are constantly the max and min values.\n",
    "        def original_tool_normalization():\n",
    "            min_value = min(pred_sOPN, pred_sCON, pred_sEXT, pred_sAGR, pred_sNEU)\n",
    "            max_value = max(pred_sOPN, pred_sCON, pred_sEXT, pred_sAGR, pred_sNEU)\n",
    "\n",
    "            scaled_min = 0.05\n",
    "            scaled_max = 0.95\n",
    "\n",
    "            pred_sOPN_normalized = (pred_sOPN - min_value) / (max_value - min_value) * (scaled_max - scaled_min) + scaled_min  # Always scores to 0.95\n",
    "            pred_sCON_normalized = (pred_sCON - min_value) / (max_value - min_value) * (scaled_max - scaled_min) + scaled_min\n",
    "            pred_sEXT_normalized = (pred_sEXT - min_value) / (max_value - min_value) * (scaled_max - scaled_min) + scaled_min\n",
    "            pred_sAGR_normalized = (pred_sAGR - min_value) / (max_value - min_value) * (scaled_max - scaled_min) + scaled_min\n",
    "            pred_sNEU_normalized = (pred_sNEU - min_value) / (max_value - min_value) * (scaled_max - scaled_min) + scaled_min  # Always scores to 0.5\n",
    "    \"\"\"\n",
    "    scaled_min = 0.05\n",
    "    scaled_max = 0.95\n",
    "\n",
    "    for column in [\"pred_sEXT\", \"pred_sNEU\", \"pred_sAGR\", \"pred_sCON\", \"pred_sOPN\"]:\n",
    "        min_value = df[column].min()\n",
    "        max_value = df[column].max()\n",
    "\n",
    "        df[f\"{column}_normalized\"] = scaled_min + (df[column] - min_value) / (\n",
    "            max_value - min_value\n",
    "        ) * (scaled_max - scaled_min)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores_by_half_threshold(scores):\n",
    "    \"\"\"\n",
    "    Used by Tool #3 & #1\n",
    "    \"\"\"\n",
    "    half_threshold = 0.5\n",
    "    return [1 if score >= half_threshold else 0 for score in scores]\n",
    "\n",
    "\n",
    "def normalize_boolean_labels_to_numerical(scores):\n",
    "    \"\"\"\n",
    "    Used by True Labels\n",
    "    \"\"\"\n",
    "    return [1 if score == \"y\" else 0 for score in scores]\n",
    "\n",
    "\n",
    "def to_int(scores):\n",
    "    \"\"\"\n",
    "    Used by Tool #4\n",
    "    \"\"\"\n",
    "    return [1 if score == 1.0 else 0 for score in scores]\n",
    "\n",
    "\n",
    "def get_tool_pearson_correlation_coefficient(\n",
    "    df, true_labels_dict, true_labels_and_tool_keys_dict, normalization_func\n",
    "):\n",
    "    tool_values_normalized = {\n",
    "        k: normalization_func(df[k].tolist())\n",
    "        for k in true_labels_and_tool_keys_dict.values()\n",
    "    }\n",
    "\n",
    "    for key in true_labels_keys:\n",
    "        res = stats.pearsonr(\n",
    "            true_labels_dict.get(key),\n",
    "            tool_values_normalized.get(true_labels_and_tool_keys_dict.get(key)),\n",
    "        )\n",
    "        print((key, true_labels_and_tool_keys_dict.get(key), res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data & Calculate Correlation Coefficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool #1\n",
      "('cEXT', 'pred_sEXT_normalized', PearsonRResult(statistic=0.02673296008862707, pvalue=0.18430024911539217))\n",
      "('cNEU', 'pred_sNEU_normalized', PearsonRResult(statistic=0.008498031063865487, pvalue=0.6730489803556491))\n",
      "('cAGR', 'pred_sAGR_normalized', PearsonRResult(statistic=0.03134768327951032, pvalue=0.11949084176053548))\n",
      "('cCON', 'pred_sCON_normalized', PearsonRResult(statistic=0.017462863261542342, pvalue=0.38585233713438616))\n",
      "('cOPN', 'pred_sOPN_normalized', PearsonRResult(statistic=0.13157584577466494, pvalue=5.3166922763821695e-11))\n",
      "\n",
      "\n",
      "Tool #3\n",
      "('cEXT', 'BIG5_Extraversion', PearsonRResult(statistic=0.05349739260942245, pvalue=0.007854700722787284))\n",
      "('cNEU', 'BIG5_Neuroticism', PearsonRResult(statistic=0.10650321988765314, pvalue=1.136783572841032e-07))\n",
      "('cAGR', 'BIG5_Agreeableness', PearsonRResult(statistic=0.047015666189085384, pvalue=0.01950175834344762))\n",
      "('cCON', 'BIG5_Conscientiousness', PearsonRResult(statistic=0.09792827656229744, pvalue=1.0923344277555917e-06))\n",
      "('cOPN', 'BIG5_Openness', PearsonRResult(statistic=0.11498558333599881, pvalue=1.0133413334400964e-08))\n",
      "\n",
      "\n",
      "Tool #4\n",
      "('cEXT', 'cEXT_prediction', PearsonRResult(statistic=0.008445269567171999, pvalue=0.6749623911088364))\n",
      "('cNEU', 'cNEU_prediction', PearsonRResult(statistic=0.02907672246563924, pvalue=0.1487178428316198))\n",
      "('cAGR', 'cAGR_prediction', PearsonRResult(statistic=0.03481866334216573, pvalue=0.08373692662316493))\n",
      "('cCON', 'cCON_prediction', PearsonRResult(statistic=0.0806033462899443, pvalue=6.103159701788963e-05))\n",
      "('cOPN', 'cOPN_prediction', PearsonRResult(statistic=0.02123404851380983, pvalue=0.2916677333083866))\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"./analysis/tools-baseline/essays-combined-predictions.xlsx\"\n",
    "\n",
    "df = pd.read_excel(input_file_path, header=1)\n",
    "true_labels_dict = {\n",
    "    k: normalize_boolean_labels_to_numerical(df[k].tolist()) for k in true_labels_keys\n",
    "}\n",
    "\n",
    "df = re_normalize_tool_1(df)\n",
    "print(\"Tool #1\")\n",
    "get_tool_pearson_correlation_coefficient(\n",
    "    df, true_labels_dict, true_and_tool1_labels, normalize_scores_by_half_threshold\n",
    ")\n",
    "print(\"\\n\\nTool #3\")\n",
    "get_tool_pearson_correlation_coefficient(\n",
    "    df, true_labels_dict, true_and_tool3_labels, normalize_scores_by_half_threshold\n",
    ")\n",
    "print(\"\\n\\nTool #4\")\n",
    "get_tool_pearson_correlation_coefficient(\n",
    "    df, true_labels_dict, true_and_tool4_labels, to_int\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyPersonality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool #1\n",
      "('cEXT', 'pred_sEXT_normalized', PearsonRResult(statistic=0.1406236278935863, pvalue=5.637647816977117e-45))\n",
      "('cNEU', 'pred_sNEU_normalized', PearsonRResult(statistic=0.18470481664709096, pvalue=7.978354703375822e-77))\n",
      "('cAGR', 'pred_sAGR_normalized', PearsonRResult(statistic=0.15572707661246574, pvalue=7.137560478676682e-55))\n",
      "('cCON', 'pred_sCON_normalized', PearsonRResult(statistic=0.16539921684497919, pvalue=9.18820908118067e-62))\n",
      "('cOPN', 'pred_sOPN_normalized', PearsonRResult(statistic=0.19872569308921464, pvalue=7.1339809047227e-89))\n",
      "\n",
      "\n",
      "Tool #3\n",
      "('cEXT', 'BIG5_Extraversion', PearsonRResult(statistic=0.06313735601501289, pvalue=3.1145807084311104e-10))\n",
      "('cNEU', 'BIG5_Neuroticism', PearsonRResult(statistic=0.10815077160013971, pvalue=3.425796319723674e-27))\n",
      "('cAGR', 'BIG5_Agreeableness', PearsonRResult(statistic=0.1226005561776652, pvalue=1.603410684420724e-34))\n",
      "('cCON', 'BIG5_Conscientiousness', PearsonRResult(statistic=0.11915681333347758, pvalue=1.0872546654038495e-32))\n",
      "('cOPN', 'BIG5_Openness', PearsonRResult(statistic=0.13222448233190628, pvalue=6.386613101487523e-40))\n",
      "\n",
      "\n",
      "Tool #4\n",
      "('cEXT', 'cEXT_prediction', PearsonRResult(statistic=0.09240430803042027, pvalue=2.955107561001348e-20))\n",
      "('cNEU', 'cNEU_prediction', PearsonRResult(statistic=0.11116901552889359, pvalue=1.2034788947984852e-28))\n",
      "('cAGR', 'cAGR_prediction', PearsonRResult(statistic=0.10492690612674825, pvalue=1.1057141650561015e-25))\n",
      "('cCON', 'cCON_prediction', PearsonRResult(statistic=0.046015825429863814, pvalue=4.5551674757231644e-06))\n",
      "('cOPN', 'cOPN_prediction', PearsonRResult(statistic=0.16743753212714882, pvalue=2.8554905207716725e-63))\n"
     ]
    }
   ],
   "source": [
    "input_file_path = (\n",
    "    \"./analysis/tools-baseline/myPersonality-concatenated-combined-predictions.xlsx\"\n",
    ")\n",
    "\n",
    "df = pd.read_excel(input_file_path, header=1)\n",
    "true_labels_dict = {\n",
    "    k: normalize_boolean_labels_to_numerical(df[k].tolist()) for k in true_labels_keys\n",
    "}\n",
    "\n",
    "df = re_normalize_tool_1(df)\n",
    "print(\"Tool #1\")\n",
    "get_tool_pearson_correlation_coefficient(\n",
    "    df, true_labels_dict, true_and_tool1_labels, normalize_scores_by_half_threshold\n",
    ")\n",
    "print(\"\\n\\nTool #3\")\n",
    "get_tool_pearson_correlation_coefficient(\n",
    "    df, true_labels_dict, true_and_tool3_labels, normalize_scores_by_half_threshold\n",
    ")\n",
    "print(\"\\n\\nTool #4\")\n",
    "get_tool_pearson_correlation_coefficient(\n",
    "    df, true_labels_dict, true_and_tool4_labels, to_int\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
