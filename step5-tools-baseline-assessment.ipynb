{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Assessment\n",
    "\n",
    "After applying the few \"state of the art\" tools and gathering their predictions on golden-standard datasets (essays & myPersonality), We'll assess result's accuracy and correlation to the datasets' true labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize The Results\n",
    "\n",
    "Combine predictions from various tools and assess\n",
    "\n",
    "First, we manually combined the results to speadsheets, against the true labels.\n",
    "The assessment spreadsheets are available here:\n",
    "\n",
    "- [Essays dataset](https://github.com/eliranshemtov/Musical-Preferences-And-Textual-Expression/blob/main/analysis/tools-baseline/essays-combined-predictions.xlsx)\n",
    "- [MyPersonality dataset](https://github.com/eliranshemtov/Musical-Preferences-And-Textual-Expression/blob/main/analysis/tools-baseline/myPersonality-combined-predictions.xlsx)\n",
    "- [MyPersonality concatenated dataset](https://github.com/eliranshemtov/Musical-Preferences-And-Textual-Expression/blob/main/analysis/tools-baseline/myPersonality-concatenated-combined-predictions.xlsx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pearson correlation coefficient\n",
    "\n",
    "is a measure of the strength and direction of the linear relationship between two quantitative variables. It is a number between -1 and 1 that measures the strength and direction of the relationship between two variables. The Pearson correlation coefficient is the most common way of measuring a linear correlation. It is a descriptive statistic, meaning that it summarizes the characteristics of a dataset. Specifically, it describes the strength and direction of the linear relationship between two quantitative variables. The formula for Pearson's correlation coefficient is the covariance of the two variables divided by the product of their standard deviations. The Pearson correlation coefficient is also an inferential statistic, meaning that it can be used to test statistical hypotheses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=-0.8285038835884277, pvalue=0.021280260007523352)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Example:\n",
    "x, y = [1, 2, 3, 4, 5, 6, 7], [10, 9, 2.5, 6, 4, 3, 2]\n",
    "res = stats.pearsonr(x, y)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score\n",
    "\n",
    "Accuracy is one metric for evaluating classification models. Informally, accuracy is the fraction of predictions our model got right. Formally, accuracy has the following definition:\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <mtext>Accuracy</mtext>\n",
    "  <mo>=</mo>\n",
    "  <mfrac>\n",
    "    <mtext>Number of correct predictions</mtext>\n",
    "    <mtext>Total number of predictions</mtext>\n",
    "  </mfrac>\n",
    "</math>\n",
    "\n",
    "For binary classification, accuracy can also be calculated in terms of positives and negatives as follows:\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "<mtext>Accuracy</mtext>\n",
    "<mo>=</mo>\n",
    "<mfrac>\n",
    "<mrow>\n",
    "<mi>T</mi>\n",
    "<mi>P</mi>\n",
    "<mo>+</mo>\n",
    "<mi>T</mi>\n",
    "<mi>N</mi>\n",
    "</mrow>\n",
    "<mrow>\n",
    "<mi>T</mi>\n",
    "<mi>P</mi>\n",
    "<mo>+</mo>\n",
    "<mi>T</mi>\n",
    "<mi>N</mi>\n",
    "<mo>+</mo>\n",
    "<mi>F</mi>\n",
    "<mi>P</mi>\n",
    "<mo>+</mo>\n",
    "<mi>F</mi>\n",
    "<mi>N</mi>\n",
    "</mrow>\n",
    "</mfrac>\n",
    "</math>\n",
    "\n",
    "Where TP = True Positives, TN = True Negatives, FP = False Positives, and FN = False Negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example:\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am going to calculate the **Pearson correlation coefficient** and **Accuracy Score** for every type of prediction of the Big Five traits, by every one of the tools I used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperations & Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_keys = [\"cEXT\", \"cNEU\", \"cAGR\", \"cCON\", \"cOPN\"]\n",
    "tool1_keys = [\n",
    "    \"pred_sEXT_normalized\",\n",
    "    \"pred_sNEU_normalized\",\n",
    "    \"pred_sAGR_normalized\",\n",
    "    \"pred_sCON_normalized\",\n",
    "    \"pred_sOPN_normalized\",\n",
    "]\n",
    "tool3_keys = [\n",
    "    \"BIG5_Extraversion\",\n",
    "    \"BIG5_Neuroticism\",\n",
    "    \"BIG5_Agreeableness\",\n",
    "    \"BIG5_Conscientiousness\",\n",
    "    \"BIG5_Openness\",\n",
    "]\n",
    "tool4_keys = [\n",
    "    \"cEXT_prediction\",\n",
    "    \"cNEU_prediction\",\n",
    "    \"cAGR_prediction\",\n",
    "    \"cCON_prediction\",\n",
    "    \"cOPN_prediction\",\n",
    "]\n",
    "\n",
    "true_and_tool1_labels = {true_labels_keys[i]: tool1_keys[i] for i in range(5)}\n",
    "true_and_tool3_labels = {true_labels_keys[i]: tool3_keys[i] for i in range(5)}\n",
    "true_and_tool4_labels = {true_labels_keys[i]: tool4_keys[i] for i in range(5)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "\n",
    "Every tool's data had to be normalized in a certain way to be used for calculations.\n",
    "\n",
    "- The True-Labels are loaded and transformed from \"y\"/\"n\" format to 0/1 format.\n",
    "- Tool #4's data is simply converted to int\n",
    "- Tool #3's data is thresholded on 0.5 (>= 0.5 is 1, otherwise 0)\n",
    "- Tool #1's data had to be re-noramalized using the following method in addition to 0.5 threshold. Details are in the method's docstring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_normalize_tool_1(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    The original normalization logic done by the actual tool is as follows and does not yield meaningful results because the prediction for OPN and NEU are constantly the max and min values.\n",
    "        def original_tool_normalization():\n",
    "            min_value = min(pred_sOPN, pred_sCON, pred_sEXT, pred_sAGR, pred_sNEU)\n",
    "            max_value = max(pred_sOPN, pred_sCON, pred_sEXT, pred_sAGR, pred_sNEU)\n",
    "\n",
    "            scaled_min = 0.05\n",
    "            scaled_max = 0.95\n",
    "\n",
    "            pred_sOPN_normalized = (pred_sOPN - min_value) / (max_value - min_value) * (scaled_max - scaled_min) + scaled_min  # Always scores to 0.95\n",
    "            pred_sCON_normalized = (pred_sCON - min_value) / (max_value - min_value) * (scaled_max - scaled_min) + scaled_min\n",
    "            pred_sEXT_normalized = (pred_sEXT - min_value) / (max_value - min_value) * (scaled_max - scaled_min) + scaled_min\n",
    "            pred_sAGR_normalized = (pred_sAGR - min_value) / (max_value - min_value) * (scaled_max - scaled_min) + scaled_min\n",
    "            pred_sNEU_normalized = (pred_sNEU - min_value) / (max_value - min_value) * (scaled_max - scaled_min) + scaled_min  # Always scores to 0.5\n",
    "    \"\"\"\n",
    "    scaled_min = 0.05\n",
    "    scaled_max = 0.95\n",
    "\n",
    "    for column in [\"pred_sEXT\", \"pred_sNEU\", \"pred_sAGR\", \"pred_sCON\", \"pred_sOPN\"]:\n",
    "        min_value = df[column].min()\n",
    "        max_value = df[column].max()\n",
    "\n",
    "        df[f\"{column}_normalized\"] = scaled_min + (df[column] - min_value) / (\n",
    "            max_value - min_value\n",
    "        ) * (scaled_max - scaled_min)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores_by_half_threshold(scores):\n",
    "    \"\"\"\n",
    "    Used by Tool #3 & #1\n",
    "    \"\"\"\n",
    "    half_threshold = 0.5\n",
    "    return [1 if score >= half_threshold else 0 for score in scores]\n",
    "\n",
    "\n",
    "def normalize_boolean_labels_to_numerical(scores):\n",
    "    \"\"\"\n",
    "    Used by True Labels\n",
    "    \"\"\"\n",
    "    return [1 if score == \"y\" else 0 for score in scores]\n",
    "\n",
    "\n",
    "def to_int(scores):\n",
    "    \"\"\"\n",
    "    Used by Tool #4\n",
    "    \"\"\"\n",
    "    return [1 if score == 1.0 else 0 for score in scores]\n",
    "\n",
    "\n",
    "def get_true_labels_and_matching_predictions(\n",
    "    df, true_labels_dict, true_labels_and_tool_keys_dict, normalization_func\n",
    "):\n",
    "    tool_values_normalized = {\n",
    "        k: normalization_func(df[k].tolist())\n",
    "        for k in true_labels_and_tool_keys_dict.values()\n",
    "    }\n",
    "\n",
    "    result = []\n",
    "    for key in true_labels_keys:\n",
    "        result.append(\n",
    "            (\n",
    "                true_labels_dict.get(key),\n",
    "                tool_values_normalized.get(true_labels_and_tool_keys_dict.get(key)),\n",
    "            )\n",
    "        )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data & Calculate Correlation Coefficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"./analysis/tools-baseline/essays-combined-predictions.xlsx\"\n",
    "\n",
    "df = pd.read_excel(input_file_path, header=1)\n",
    "true_labels_dict = {\n",
    "    k: normalize_boolean_labels_to_numerical(df[k].tolist()) for k in true_labels_keys\n",
    "}\n",
    "\n",
    "df = re_normalize_tool_1(df)\n",
    "true_labels_with_tool1_tuple = get_true_labels_and_matching_predictions(\n",
    "    df, true_labels_dict, true_and_tool1_labels, normalize_scores_by_half_threshold\n",
    ")\n",
    "true_labels_with_tool3_tuple = get_true_labels_and_matching_predictions(\n",
    "    df, true_labels_dict, true_and_tool3_labels, normalize_scores_by_half_threshold\n",
    ")\n",
    "true_labels_with_tool4_tuple = get_true_labels_and_matching_predictions(\n",
    "    df, true_labels_dict, true_and_tool4_labels, to_int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool #1\n",
      "Correlation Coefficient for: cEXT PearsonRResult(statistic=0.02673296008862707, pvalue=0.18430024911539217)\n",
      "Accuracy for: cEXT 0.5214748784440842\n",
      "Correlation Coefficient for: cNEU PearsonRResult(statistic=0.008498031063865487, pvalue=0.6730489803556491)\n",
      "Accuracy for: cNEU 0.5040518638573744\n",
      "Correlation Coefficient for: cAGR PearsonRResult(statistic=0.03134768327951032, pvalue=0.11949084176053548)\n",
      "Accuracy for: cAGR 0.5072933549432739\n",
      "Correlation Coefficient for: cCON PearsonRResult(statistic=0.017462863261542342, pvalue=0.38585233713438616)\n",
      "Accuracy for: cCON 0.5113452188006483\n",
      "Correlation Coefficient for: cOPN PearsonRResult(statistic=0.13157584577466494, pvalue=5.3166922763821695e-11)\n",
      "Accuracy for: cOPN 0.5672609400324149\n",
      "\n",
      "\n",
      "\n",
      "Tool #3\n",
      "Correlation Coefficient for: cEXT PearsonRResult(statistic=0.05349739260942245, pvalue=0.007854700722787284)\n",
      "Accuracy for: cEXT 0.4959481361426256\n",
      "Correlation Coefficient for: cNEU PearsonRResult(statistic=0.10650321988765314, pvalue=1.136783572841032e-07)\n",
      "Accuracy for: cNEU 0.549837925445705\n",
      "Correlation Coefficient for: cAGR PearsonRResult(statistic=0.047015666189085384, pvalue=0.01950175834344762)\n",
      "Accuracy for: cAGR 0.5101296596434359\n",
      "Correlation Coefficient for: cCON PearsonRResult(statistic=0.09792827656229744, pvalue=1.0923344277555917e-06)\n",
      "Accuracy for: cCON 0.5388978930307942\n",
      "Correlation Coefficient for: cOPN PearsonRResult(statistic=0.11498558333599881, pvalue=1.0133413334400964e-08)\n",
      "Accuracy for: cOPN 0.5575364667747164\n",
      "\n",
      "\n",
      "\n",
      "Tool #4\n",
      "Correlation Coefficient for: cEXT PearsonRResult(statistic=0.008445269567171999, pvalue=0.6749623911088364)\n",
      "Accuracy for: cEXT 0.5145867098865479\n",
      "Correlation Coefficient for: cNEU PearsonRResult(statistic=0.02907672246563924, pvalue=0.1487178428316198)\n",
      "Accuracy for: cNEU 0.5113452188006483\n",
      "Correlation Coefficient for: cAGR PearsonRResult(statistic=0.03481866334216573, pvalue=0.08373692662316493)\n",
      "Accuracy for: cAGR 0.5121555915721232\n",
      "Correlation Coefficient for: cCON PearsonRResult(statistic=0.0806033462899443, pvalue=6.103159701788963e-05)\n",
      "Accuracy for: cCON 0.5324149108589952\n",
      "Correlation Coefficient for: cOPN PearsonRResult(statistic=0.02123404851380983, pvalue=0.2916677333083866)\n",
      "Accuracy for: cOPN 0.5178282009724473\n"
     ]
    }
   ],
   "source": [
    "print(\"Tool #1\")\n",
    "for i in range(len(true_labels_with_tool1_tuple)):\n",
    "    print(\n",
    "        f\"Correlation Coefficient for: {true_labels_keys[i]}\",\n",
    "        stats.pearsonr(*true_labels_with_tool1_tuple[i]),\n",
    "    )\n",
    "    print(\n",
    "        f\"Accuracy for: {true_labels_keys[i]}\",\n",
    "        accuracy_score(*true_labels_with_tool1_tuple[i]),\n",
    "    )\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Tool #3\")\n",
    "for i in range(len(true_labels_with_tool3_tuple)):\n",
    "    print(\n",
    "        f\"Correlation Coefficient for: {true_labels_keys[i]}\",\n",
    "        stats.pearsonr(*true_labels_with_tool3_tuple[i]),\n",
    "    )\n",
    "    print(\n",
    "        f\"Accuracy for: {true_labels_keys[i]}\",\n",
    "        accuracy_score(*true_labels_with_tool3_tuple[i]),\n",
    "    )\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Tool #4\")\n",
    "for i in range(len(true_labels_with_tool4_tuple)):\n",
    "    print(\n",
    "        f\"Correlation Coefficient for: {true_labels_keys[i]}\",\n",
    "        stats.pearsonr(*true_labels_with_tool4_tuple[i]),\n",
    "    )\n",
    "    print(\n",
    "        f\"Accuracy for: {true_labels_keys[i]}\",\n",
    "        accuracy_score(*true_labels_with_tool4_tuple[i]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MyPersonality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = (\n",
    "    \"./analysis/tools-baseline/myPersonality-concatenated-combined-predictions.xlsx\"\n",
    ")\n",
    "\n",
    "df = pd.read_excel(input_file_path, header=1)\n",
    "true_labels_dict = {\n",
    "    k: normalize_boolean_labels_to_numerical(df[k].tolist()) for k in true_labels_keys\n",
    "}\n",
    "\n",
    "df = re_normalize_tool_1(df)\n",
    "true_labels_with_tool1_tuple = get_true_labels_and_matching_predictions(\n",
    "    df, true_labels_dict, true_and_tool1_labels, normalize_scores_by_half_threshold\n",
    ")\n",
    "true_labels_with_tool3_tuple = get_true_labels_and_matching_predictions(\n",
    "    df, true_labels_dict, true_and_tool3_labels, normalize_scores_by_half_threshold\n",
    ")\n",
    "true_labels_with_tool4_tuple = get_true_labels_and_matching_predictions(\n",
    "    df, true_labels_dict, true_and_tool4_labels, to_int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool #1\n",
      "Correlation Coefficient for: cEXT PearsonRResult(statistic=0.1406236278935863, pvalue=5.637647816977117e-45)\n",
      "Accuracy for: cEXT 0.849450438640718\n",
      "Correlation Coefficient for: cNEU PearsonRResult(statistic=0.18470481664709096, pvalue=7.978354703375822e-77)\n",
      "Accuracy for: cNEU 0.8732479580518302\n",
      "Correlation Coefficient for: cAGR PearsonRResult(statistic=0.15572707661246574, pvalue=7.137560478676682e-55)\n",
      "Accuracy for: cAGR 0.8175859634970253\n",
      "Correlation Coefficient for: cCON PearsonRResult(statistic=0.16539921684497919, pvalue=9.18820908118067e-62)\n",
      "Accuracy for: cCON 0.820611071896743\n",
      "Correlation Coefficient for: cOPN PearsonRResult(statistic=0.19872569308921464, pvalue=7.1339809047227e-89)\n",
      "Accuracy for: cOPN 0.7686800443682565\n",
      "\n",
      "\n",
      "\n",
      "Tool #3\n",
      "Correlation Coefficient for: cEXT PearsonRResult(statistic=0.06313735601501289, pvalue=3.1145807084311104e-10)\n",
      "Accuracy for: cEXT 0.8480387213875163\n",
      "Correlation Coefficient for: cNEU PearsonRResult(statistic=0.10815077160013971, pvalue=3.425796319723674e-27)\n",
      "Accuracy for: cNEU 0.8668952304124231\n",
      "Correlation Coefficient for: cAGR PearsonRResult(statistic=0.1226005561776652, pvalue=1.603410684420724e-34)\n",
      "Accuracy for: cAGR 0.8165775940304527\n",
      "Correlation Coefficient for: cCON PearsonRResult(statistic=0.11915681333347758, pvalue=1.0872546654038495e-32)\n",
      "Accuracy for: cCON 0.8176868004436826\n",
      "Correlation Coefficient for: cOPN PearsonRResult(statistic=0.13222448233190628, pvalue=6.386613101487523e-40)\n",
      "Accuracy for: cOPN 0.7611172733689624\n",
      "\n",
      "\n",
      "\n",
      "Tool #4\n",
      "Correlation Coefficient for: cEXT PearsonRResult(statistic=0.09240430803042027, pvalue=2.955107561001348e-20)\n",
      "Accuracy for: cEXT 0.8437027326812544\n",
      "Correlation Coefficient for: cNEU PearsonRResult(statistic=0.11116901552889359, pvalue=1.2034788947984852e-28)\n",
      "Accuracy for: cNEU 0.8627609155994757\n",
      "Correlation Coefficient for: cAGR PearsonRResult(statistic=0.10492690612674825, pvalue=1.1057141650561015e-25)\n",
      "Accuracy for: cAGR 0.815468387617223\n",
      "Correlation Coefficient for: cCON PearsonRResult(statistic=0.046015825429863814, pvalue=4.5551674757231644e-06)\n",
      "Accuracy for: cCON 0.8145608550973077\n",
      "Correlation Coefficient for: cOPN PearsonRResult(statistic=0.16743753212714882, pvalue=2.8554905207716725e-63)\n",
      "Accuracy for: cOPN 0.7646465665019663\n"
     ]
    }
   ],
   "source": [
    "print(\"Tool #1\")\n",
    "for i in range(len(true_labels_with_tool1_tuple)):\n",
    "    print(\n",
    "        f\"Correlation Coefficient for: {true_labels_keys[i]}\",\n",
    "        stats.pearsonr(*true_labels_with_tool1_tuple[i]),\n",
    "    )\n",
    "    print(\n",
    "        f\"Accuracy for: {true_labels_keys[i]}\",\n",
    "        accuracy_score(*true_labels_with_tool1_tuple[i]),\n",
    "    )\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Tool #3\")\n",
    "for i in range(len(true_labels_with_tool3_tuple)):\n",
    "    print(\n",
    "        f\"Correlation Coefficient for: {true_labels_keys[i]}\",\n",
    "        stats.pearsonr(*true_labels_with_tool3_tuple[i]),\n",
    "    )\n",
    "    print(\n",
    "        f\"Accuracy for: {true_labels_keys[i]}\",\n",
    "        accuracy_score(*true_labels_with_tool3_tuple[i]),\n",
    "    )\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Tool #4\")\n",
    "for i in range(len(true_labels_with_tool4_tuple)):\n",
    "    print(\n",
    "        f\"Correlation Coefficient for: {true_labels_keys[i]}\",\n",
    "        stats.pearsonr(*true_labels_with_tool4_tuple[i]),\n",
    "    )\n",
    "    print(\n",
    "        f\"Accuracy for: {true_labels_keys[i]}\",\n",
    "        accuracy_score(*true_labels_with_tool4_tuple[i]),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
