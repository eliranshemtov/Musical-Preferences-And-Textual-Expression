{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forming Personality Traits Baseline\n",
    "\n",
    "## By assessing existing tools' predictions\n",
    "\n",
    "The data that will be assessed in this section will be: [essays.zip](\"http://web.archive.org/web/20160519045708/http://mypersonality.org/wiki/lib/exe/fetch.php?media=wiki:essays.zip\"): a large dataset of 2400 stream-of-consciousness texts labelled with personality, produced by Pennebaker & King 1999 and used by Mairesse et al. 2007.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool #1 - https://project.fuguixing.me/\n",
    "\n",
    "A web application for personality analysis, Big Five personality prediction, and emotion analysis. Powered by Azure Static Web App, Azure Function, React, and Machine Learning\n",
    "Sourced at: https://github.com/fuguixing/psychology-insights-frontend/tree/master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2468it [00:02, 1171.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file with added columns created: ./analysis/tool-1-baseline.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "api_url = \"https://project.fuguixing.me/api/bigfive\"\n",
    "essays_data_csv_file_path = \"./data/essays.csv\"\n",
    "result_file_path = \"./analysis/tool-1-baseline.csv\"\n",
    "\n",
    "\n",
    "with open(essays_data_csv_file_path, newline=\"\", encoding=\"ISO-8859-1\") as csvfile:\n",
    "    csv_reader = csv.DictReader(csvfile, delimiter=\",\")\n",
    "    fieldnames = csv_reader.fieldnames + [\n",
    "        \"pred_sOPN\",\n",
    "        \"pred_sOPN_normalized\",\n",
    "        \"pred_sCON\",\n",
    "        \"pred_sCON_normalized\",\n",
    "        \"pred_sEXT\",\n",
    "        \"pred_sEXT_normalized\",\n",
    "        \"pred_sAGR\",\n",
    "        \"pred_sAGR_normalized\",\n",
    "        \"pred_sNEU\",\n",
    "        \"pred_sNEU_normalized\",\n",
    "        \"pred_sentiment\",\n",
    "    ]\n",
    "\n",
    "    with open(result_file_path, \"w\", newline=\"\", encoding=\"utf-8\") as updated_csvfile:\n",
    "        csv_writer = csv.DictWriter(\n",
    "            updated_csvfile, fieldnames=fieldnames, delimiter=\"\\t\"\n",
    "        )\n",
    "        csv_writer.writeheader()\n",
    "\n",
    "        for row in tqdm(csv_reader):\n",
    "            payload = f'\"{row.get(\"TEXT\")}\"'\n",
    "            headers = {\"Content-Type\": \"text/plain\"}\n",
    "            response = requests.post(\n",
    "                api_url, data=json.dumps(payload), headers=headers)\n",
    "            new_values = {}\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                api_data = response.json()\n",
    "                prediction = api_data.get(\"prediction\", {})\n",
    "                new_values.update(prediction)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"POST request failed for row with ID {row['#AUTHID']}. Status code: {response.status_code}\"\n",
    "                )\n",
    "\n",
    "            row.update(new_values)\n",
    "            csv_writer.writerow(row)\n",
    "            time.sleep(1)\n",
    "\n",
    "print(f\"CSV file with added columns created: {result_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool #2 - [Personality Recognizer v1.03](http://farm2.user.srcf.net/research/personality/recognizer.html)\n",
    "\n",
    "# ⚠️ Aborted. Poor & Outdated results\n",
    "\n",
    "This work is a bit old [Mairesse et al., 2007](http://farm2.user.srcf.net/research/papers/personality-jair07.pdf), however, acts as a real black-box.\n",
    "This Java program is based on models analyzed in the paper, and shown to predict personality scores significantly better than a constant baseline. The program uses a command line interface, and outputs scores on a scale from 1 to 7, e.g. where 7 is strongly extravert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll parse the essays.csv dataset and convert it to a folder of txt files, as this program expects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "csv_file_path = \"./data/essays.csv\"\n",
    "output_folder = \"./data/essays_as_txt\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with open(csv_file_path, newline=\"\", encoding=\"ISO-8859-1\") as csvfile:\n",
    "    csv_reader = csv.DictReader(\n",
    "        csvfile, delimiter=\",\", quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        auth_id = row.get(\"#AUTHID\", \"\")\n",
    "        text_data = row.get('\"TEXT\"', \"\")\n",
    "\n",
    "        if auth_id and text_data:\n",
    "            txt_file_path = os.path.join(output_folder, f\"{auth_id}.txt\")\n",
    "\n",
    "            with open(txt_file_path, \"w\", encoding=\"utf-8\") as txtfile:\n",
    "                txtfile.write(text_data)\n",
    "\n",
    "print(\"TXT files saved in the output folder:\", output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As this package is old and un-maintained, it requires significant effort to run it. The assessment results for the essays.csv dataset is detailed in the original [article](http://farm2.user.srcf.net/research/papers/personality-jair07.pdf) (page 19/44)\n",
    "\n",
    "\"Classification results for the essays corpus with self-reports are in Table 12. Interestingly,\n",
    "openness to experience is the easiest trait to model as five classifiers out of six significantly\n",
    "outperform the baseline and four of them produce their best performance for that trait,\n",
    "with accuracies up to 62.1% using support vector machines (SMO). Emotional stability\n",
    "produces the second best performance for four classifiers out of six, with 57.4% accuracy\n",
    "for the SMO model. Conscientiousness is the hardest trait to model as only two classifiers\n",
    "significantly outperform the baseline, however the SMO model performs as well as the best\n",
    "model for extraversion and agreeableness, with around 55% correct classifications.\n",
    "We find that support vector machines generally perform the best, with Naive Bayes and\n",
    "AdaboostM1 in second position. SMO significantly outperforms the majority class baseline\n",
    "for each trait. A J48 decision tree for recognising extraversion is shown in Figure 1, and the\n",
    "rule-based JRip model classifying openness to experience with 58.8% accuracy is illustrated\n",
    "in Table 16.\"\n",
    "\n",
    "We can try and utilize this Java app if the results looks interesting enough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool #3 Apply Magic Sauce\n",
    "\n",
    "Apply Magic Sauce is a non-profit academic research project coordinated by the University of Cambridge Psychometrics Centre.\n",
    "The project aimed to analyze and predict individuals' psychological traits, such as personality, based on their digital footprints, including social media activity, likes, and other online behaviors. The project utilized advanced algorithms and machine learning techniques to make predictions about users' personalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2468it [51:59,  1.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file with added columns created: ./analysis/tool-3-baseline.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from calendar import c\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "api_url = \"https://applymagicsauce.com/api/predictions/text\"\n",
    "api_token = \"eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiI3YTAzOWU4MC0yYWUzLTRlMmEtOWZlMi00ZTc0MmU5NjczYWMiLCJjdXJyZW50VXNlciI6eyJpZCI6IjdhMDM5ZTgwLTJhZTMtNGUyYS05ZmUyLTRlNzQyZTk2NzNhYyIsInJvbGUiOiJVU0VSIiwiYXV0aG9yaXRpZXMiOlsiUk9MRV9VU0VSIl19LCJleHAiOjE2OTcyNzE5MDh9.hngcBBlQLxHqm9pX7r-3r4zVPCJFybJ2eryUkPIytQZOF65V5dN6PMxa6TVehoHWq8-6l1ZW6TwcaSeN0uPg5w\"\n",
    "essays_data_csv_file_path = \"./data/essays.csv\"\n",
    "result_file_path = \"./analysis/tool-3-baseline.csv\"\n",
    "\n",
    "predictions_fields = [\n",
    "    \"BIG5_Openness\",\n",
    "    \"BIG5_Conscientiousness\",\n",
    "    \"BIG5_Extraversion\",\n",
    "    \"BIG5_Agreeableness\",\n",
    "    \"BIG5_Neuroticism\",\n",
    "    \"Female\",\n",
    "    \"Age\",\n",
    "]\n",
    "with open(essays_data_csv_file_path, newline=\"\", encoding=\"ISO-8859-1\") as csvfile:\n",
    "    csv_reader = csv.DictReader(csvfile, delimiter=\",\")\n",
    "    fieldnames = csv_reader.fieldnames + predictions_fields\n",
    "\n",
    "    with open(result_file_path, \"w\", newline=\"\", encoding=\"utf-8\") as updated_csvfile:\n",
    "        csv_writer = csv.DictWriter(\n",
    "            updated_csvfile, fieldnames=fieldnames, delimiter=\",\"\n",
    "        )\n",
    "        csv_writer.writeheader()\n",
    "        count = 0\n",
    "        for row in tqdm(csv_reader):\n",
    "\n",
    "            if count < 1922:\n",
    "                count += 1\n",
    "                continue\n",
    "            payload = f'\"{row.get(\"TEXT\")}\"'\n",
    "            headers = {\n",
    "                \"Content-Type\": \"text/plain\",\n",
    "                \"Authorization\": f\"Bearer {api_token}\",\n",
    "            }\n",
    "            response = requests.post(\n",
    "                api_url, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                api_data = response.json()\n",
    "                prediction = {\n",
    "                    i.get(\"trait\"): i.get(\"value\") for i in api_data.get(\"predictions\")\n",
    "                }\n",
    "                new_values.update(prediction)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"POST request failed for row with ID {row['#AUTHID']}. Status code: {response.status_code}\"\n",
    "                )\n",
    "\n",
    "            row.update(new_values)\n",
    "            count += 1\n",
    "            try:\n",
    "                del row['trait']\n",
    "            except:\n",
    "                pass\n",
    "            csv_writer.writerow(row)\n",
    "            time.sleep(1)\n",
    "\n",
    "print(f\"CSV file with added columns created: {result_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
