{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the dataset with vectors (E5-Large)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load & Process\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Load as DF and filter out by tokens threshold (40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "12"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 523.97it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 823.92it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 627.96it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 834.89it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 732.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done processing texts :)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "df = pd.DataFrame(columns=[\"community\", \"user_name\", \"user_texts\", \"#_of_long_texts\"])\n",
        "\n",
        "\n",
        "def process_files(community, df):\n",
        "    threshold = 40\n",
        "    directory = f\"../data/detailed_filtered_data/texts/{community}\"\n",
        "    for filename in tqdm(os.listdir(directory)):\n",
        "        if filename.endswith(\".json\"):\n",
        "            user_texts = []\n",
        "            with open(os.path.join(directory, filename), \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                for key in data:\n",
        "                    for submission in data[key].get(\"submissions\", []):\n",
        "                        title = submission.get(\"title\", \"\")\n",
        "                        body = submission.get(\"body\", \"\")\n",
        "                        if len(title.split()) >= threshold:\n",
        "                            user_texts.append(title)\n",
        "                        if len(body.split()) >= threshold:\n",
        "                            user_texts.append(body)\n",
        "                    for submission in data[key].get(\"comments\", []):\n",
        "                        body = submission.get(\"body\", \"\")\n",
        "                        if len(body.split()) >= threshold:\n",
        "                            user_texts.append(body)\n",
        "            if len(user_texts) == 0:\n",
        "                continue\n",
        "            user_name = filename.split(\".json\")[0]\n",
        "            new_row = pd.DataFrame(\n",
        "                {\n",
        "                    \"community\": community,\n",
        "                    \"user_name\": [user_name],\n",
        "                    \"user_texts\": [user_texts],\n",
        "                    \"#_of_long_texts\": [len(user_texts)],\n",
        "                }\n",
        "            )\n",
        "            df = pd.concat([df, new_row], ignore_index=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "communities = [\n",
        "    \"classicalmusic\",\n",
        "    \"electronicmusic\",\n",
        "    \"hiphopheads\",\n",
        "    \"indieheads\",\n",
        "    \"Metal\",\n",
        "]\n",
        "\n",
        "for vector_file_name in communities:\n",
        "    df = pd.concat([df, process_files(vector_file_name, df)])\n",
        "print(\"Done processing texts :)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 De-Duplication\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "12"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After dedeuplication there are 575,816 unique texts in total\n"
          ]
        }
      ],
      "source": [
        "def deduplicate_texts(df):\n",
        "    exploded_df = df.explode(\"user_texts\")\n",
        "    exploded_df = exploded_df.drop_duplicates(subset=\"user_texts\")\n",
        "    return exploded_df\n",
        "\n",
        "\n",
        "df = deduplicate_texts(df)\n",
        "print(\"After dedeuplication there are\", format(len(df), \",\"), \"unique texts in total\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Split DF by Genre\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "12"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of texts left after deduplication per community: \n",
            "Classicalmusic: 170,251 \n",
            "Electronicmusic: 97,063 \n",
            "Hiphopheads: 121,538 \n",
            "Indieheads: 84,314 \n",
            "Metal: 102,650\n"
          ]
        }
      ],
      "source": [
        "classicalmusic_df = df[df[\"community\"] == \"classicalmusic\"]\n",
        "electronicmusic_df = df[df[\"community\"] == \"electronicmusic\"]\n",
        "hiphopheads_df = df[df[\"community\"] == \"hiphopheads\"]\n",
        "indieheads_df = df[df[\"community\"] == \"indieheads\"]\n",
        "metal_df = df[df[\"community\"] == \"Metal\"]\n",
        "\n",
        "communities_dfs = [\n",
        "    classicalmusic_df,\n",
        "    electronicmusic_df,\n",
        "    hiphopheads_df,\n",
        "    indieheads_df,\n",
        "    metal_df,\n",
        "]\n",
        "\n",
        "print(\n",
        "    \"Number of texts left after deduplication per community:\",\n",
        "    \"\\nClassicalmusic:\",\n",
        "    format(len(classicalmusic_df), \",\"),\n",
        "    \"\\nElectronicmusic:\",\n",
        "    format(len(electronicmusic_df), \",\"),\n",
        "    \"\\nHiphopheads:\",\n",
        "    format(len(hiphopheads_df), \",\"),\n",
        "    \"\\nIndieheads:\",\n",
        "    format(len(indieheads_df), \",\"),\n",
        "    \"\\nMetal:\",\n",
        "    format(len(metal_df), \",\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Text-Count per user\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "12"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Median and Mean of texts-count per user in each community after deduplication:\n",
            "classicalmusic: Median = 118.5  | Mean = 173.37\n",
            "electronicmusic: Median = 60.5  | Mean = 109.55\n",
            "hiphopheads: Median = 83.0  | Mean = 122.39\n",
            "indieheads: Median = 52.0  | Mean = 96.8\n",
            "metal: Median = 58.0  | Mean = 107.94\n"
          ]
        }
      ],
      "source": [
        "classicalmusic_counts = classicalmusic_df[\"user_name\"].value_counts()\n",
        "electronicmusic_counts = electronicmusic_df[\"user_name\"].value_counts()\n",
        "hiphopheads_counts = hiphopheads_df[\"user_name\"].value_counts()\n",
        "indieheads_counts = indieheads_df[\"user_name\"].value_counts()\n",
        "metal_counts = metal_df[\"user_name\"].value_counts()\n",
        "\n",
        "\n",
        "print(\"Median and Mean of texts-count per user in each community after deduplication:\")\n",
        "print(\n",
        "    \"classicalmusic: Median =\",\n",
        "    classicalmusic_counts.median(),\n",
        "    \" | Mean =\",\n",
        "    round(classicalmusic_counts.mean(), 2),\n",
        ")\n",
        "print(\n",
        "    \"electronicmusic: Median =\",\n",
        "    electronicmusic_counts.median(),\n",
        "    \" | Mean =\",\n",
        "    round(electronicmusic_counts.mean(), 2),\n",
        ")\n",
        "print(\n",
        "    \"hiphopheads: Median =\",\n",
        "    hiphopheads_counts.median(),\n",
        "    \" | Mean =\",\n",
        "    round(hiphopheads_counts.mean(), 2),\n",
        ")\n",
        "print(\n",
        "    \"indieheads: Median =\",\n",
        "    indieheads_counts.median(),\n",
        "    \" | Mean =\",\n",
        "    round(indieheads_counts.mean(), 2),\n",
        ")\n",
        "print(\n",
        "    \"metal: Median =\", metal_counts.median(), \" | Mean =\", round(metal_counts.mean(), 2)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Vectorize all Redditors texts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Vectorize\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.1.1 Vectorization method\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from typing import List, Union\n",
        "from torch import Tensor\n",
        "from numpy import ndarray\n",
        "\n",
        "\n",
        "def vectorize_text(\n",
        "    text, model: SentenceTransformer, batch_size=12, show_progress_bar=False\n",
        ") -> Union[List[Tensor], ndarray, Tensor]:\n",
        "    return model.encode(\n",
        "        text, show_progress_bar=show_progress_bar, batch_size=batch_size\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.1.2 Vectorize & persist or reload (method only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "MODEL = \"intfloat/e5-large-v2\"\n",
        "\n",
        "model = SentenceTransformer(MODEL)\n",
        "\n",
        "\n",
        "def vectorize_or_load_community_data(community_name: str, df: pd.DataFrame):\n",
        "    file_path = f\"../data/detailed_filtered_data/vectors/{community_name}.h5\"\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"Loading vectors for {community_name} from file\")\n",
        "        with h5py.File(file_path, \"r\") as f:\n",
        "            dataset = f[\"vectors\"]\n",
        "            df[\"vector\"] = dataset[:].tolist()\n",
        "    else:\n",
        "        print(f\"Vectorizing texts for {community_name}...\")\n",
        "        compression = \"lzf\"\n",
        "        estimated_rows = len(df)\n",
        "\n",
        "        with h5py.File(file_path, \"a\") as f:\n",
        "            if \"vectors\" not in f:\n",
        "                dataset = f.create_dataset(\n",
        "                    \"vectors\",\n",
        "                    (estimated_rows, model.get_sentence_embedding_dimension()),\n",
        "                    dtype=np.float32,\n",
        "                    compression=compression,\n",
        "                )\n",
        "                print(\"Dataset shape:\", dataset.shape)\n",
        "            else:\n",
        "                dataset = f[\"vectors\"]\n",
        "\n",
        "            i = 0\n",
        "            progress_bar = tqdm(total=estimated_rows, desc=\"Vectorizing texts\")\n",
        "            for _, row in df.iterrows():\n",
        "                vector = vectorize_text(row[\"user_texts\"], model)\n",
        "                dataset[i] = vector\n",
        "                i += 1\n",
        "                progress_bar.update(1)\n",
        "            progress_bar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.1.3 Load vectors (or vectorize)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading vectors for classical from file\n",
            "Loading vectors for electronic from file\n",
            "Loading vectors for hiphopheads from file\n",
            "Loading vectors for indieheads from file\n",
            "Loading vectors for metal from file\n"
          ]
        }
      ],
      "source": [
        "community_names = [\"classical\", \"electronic\", \"hiphopheads\", \"indieheads\", \"metal\"]\n",
        "for community_name, df in zip(community_names, communities_dfs):\n",
        "    vectorize_or_load_community_data(community_name, df)\n",
        "df = pd.concat(communities_dfs, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Show Sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "12"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>community</th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_texts</th>\n",
              "      <th>#_of_long_texts</th>\n",
              "      <th>vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>classicalmusic</td>\n",
              "      <td>Radaxen</td>\n",
              "      <td>I remember doing this with WC3 Dota 1 Lifestea...</td>\n",
              "      <td>339</td>\n",
              "      <td>[-0.0013457498280331492, -0.06375082582235336,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>classicalmusic</td>\n",
              "      <td>Radaxen</td>\n",
              "      <td>Why not? Though there's no AD in League.  I ki...</td>\n",
              "      <td>339</td>\n",
              "      <td>[0.018474051728844643, -0.01666010357439518, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>classicalmusic</td>\n",
              "      <td>Radaxen</td>\n",
              "      <td>Haha I was kind of joking. That aside, why mos...</td>\n",
              "      <td>339</td>\n",
              "      <td>[-0.008903076872229576, -0.05069487541913986, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>classicalmusic</td>\n",
              "      <td>Radaxen</td>\n",
              "      <td>Mana is often a less limiting factor, unless y...</td>\n",
              "      <td>339</td>\n",
              "      <td>[0.04738666117191315, -0.053208597004413605, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>classicalmusic</td>\n",
              "      <td>Radaxen</td>\n",
              "      <td>It's first pick worthy, but late in first phas...</td>\n",
              "      <td>339</td>\n",
              "      <td>[0.007831799797713757, -0.0637780949473381, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        community user_name  \\\n",
              "0  classicalmusic   Radaxen   \n",
              "1  classicalmusic   Radaxen   \n",
              "2  classicalmusic   Radaxen   \n",
              "3  classicalmusic   Radaxen   \n",
              "4  classicalmusic   Radaxen   \n",
              "\n",
              "                                          user_texts #_of_long_texts  \\\n",
              "0  I remember doing this with WC3 Dota 1 Lifestea...             339   \n",
              "1  Why not? Though there's no AD in League.  I ki...             339   \n",
              "2  Haha I was kind of joking. That aside, why mos...             339   \n",
              "3  Mana is often a less limiting factor, unless y...             339   \n",
              "4  It's first pick worthy, but late in first phas...             339   \n",
              "\n",
              "                                              vector  \n",
              "0  [-0.0013457498280331492, -0.06375082582235336,...  \n",
              "1  [0.018474051728844643, -0.01666010357439518, 0...  \n",
              "2  [-0.008903076872229576, -0.05069487541913986, ...  \n",
              "3  [0.04738666117191315, -0.053208597004413605, 0...  \n",
              "4  [0.007831799797713757, -0.0637780949473381, 0....  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Predict personality traits presence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Load the traits models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "traits_and_models = {\"opn\": None, \"ext\": None, \"neu\": None, \"agr\": None, \"con\": None}\n",
        "\n",
        "for trait in traits_and_models.keys():\n",
        "    with open(f\"../models/step-10/gpt_{trait}.pkl\", \"rb\") as f:\n",
        "        traits_and_models[trait] = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Predict-Probablily per trait\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "1"
        }
      },
      "outputs": [],
      "source": [
        "def predict_trait_probab(trait: str, df: pd.DataFrame, model: LogisticRegression):\n",
        "    df[f\"{trait}_proba\"] = df[\"vector\"].apply(\n",
        "        lambda x: model.predict_proba(np.array(x).reshape(1, -1))\n",
        "    )\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "for trait, model in traits_and_models.items():\n",
        "    df = predict_trait_probab(trait, df, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# That's it!\n",
        "\n",
        "The dataset is loaded, along with the texts' vectors and the presence probability prediction per personality trait\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>community</th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_texts</th>\n",
              "      <th>#_of_long_texts</th>\n",
              "      <th>vector</th>\n",
              "      <th>opn_proba</th>\n",
              "      <th>ext_proba</th>\n",
              "      <th>neu_proba</th>\n",
              "      <th>agr_proba</th>\n",
              "      <th>con_proba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>classicalmusic</td>\n",
              "      <td>Radaxen</td>\n",
              "      <td>I remember doing this with WC3 Dota 1 Lifestea...</td>\n",
              "      <td>339</td>\n",
              "      <td>[-0.0013457498280331492, -0.06375082582235336,...</td>\n",
              "      <td>[[0.4633694992256616, 0.5366305007743384]]</td>\n",
              "      <td>[[0.4047406305005551, 0.5952593694994449]]</td>\n",
              "      <td>[[0.5133525548832986, 0.48664744511670144]]</td>\n",
              "      <td>[[0.2907748902422237, 0.7092251097577763]]</td>\n",
              "      <td>[[0.3720289946657592, 0.6279710053342408]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170251</th>\n",
              "      <td>electronicmusic</td>\n",
              "      <td>headphase</td>\n",
              "      <td>This Monday, June 12, r/BedStuy will become un...</td>\n",
              "      <td>305</td>\n",
              "      <td>[0.011666242964565754, -0.035366132855415344, ...</td>\n",
              "      <td>[[0.4260546229680149, 0.5739453770319851]]</td>\n",
              "      <td>[[0.6087019486538947, 0.39129805134610535]]</td>\n",
              "      <td>[[0.5780140586341542, 0.4219859413658457]]</td>\n",
              "      <td>[[0.24227405375973832, 0.7577259462402617]]</td>\n",
              "      <td>[[0.23508181739111556, 0.7649181826088844]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267314</th>\n",
              "      <td>hiphopheads</td>\n",
              "      <td>thanks_bruh</td>\n",
              "      <td>Whats good yâ€™all. Iâ€™m looking to make friends ...</td>\n",
              "      <td>50</td>\n",
              "      <td>[0.028840450569987297, -0.06617984920740128, 0...</td>\n",
              "      <td>[[0.5274351693681876, 0.4725648306318124]]</td>\n",
              "      <td>[[0.5410485410530944, 0.4589514589469056]]</td>\n",
              "      <td>[[0.36379346487378283, 0.6362065351262172]]</td>\n",
              "      <td>[[0.37324202653229677, 0.6267579734677032]]</td>\n",
              "      <td>[[0.31871618922553135, 0.6812838107744686]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388852</th>\n",
              "      <td>indieheads</td>\n",
              "      <td>simco1974</td>\n",
              "      <td>2008 or so, I was digging around at a local re...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.024371720850467682, -0.05200977995991707, 0...</td>\n",
              "      <td>[[0.5114953603142274, 0.4885046396857727]]</td>\n",
              "      <td>[[0.4437402015227965, 0.5562597984772035]]</td>\n",
              "      <td>[[0.42615630341430943, 0.5738436965856906]]</td>\n",
              "      <td>[[0.37897041332216275, 0.6210295866778373]]</td>\n",
              "      <td>[[0.33153541480610726, 0.6684645851938927]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473166</th>\n",
              "      <td>Metal</td>\n",
              "      <td>sam1oq</td>\n",
              "      <td>I found out that apparently I was still paying...</td>\n",
              "      <td>309</td>\n",
              "      <td>[0.024809353053569794, -0.036989957094192505, ...</td>\n",
              "      <td>[[0.38509045003141096, 0.614909549968589]]</td>\n",
              "      <td>[[0.5761465262055332, 0.42385347379446686]]</td>\n",
              "      <td>[[0.6205980989623865, 0.3794019010376135]]</td>\n",
              "      <td>[[0.21988913688937062, 0.7801108631106294]]</td>\n",
              "      <td>[[0.20360275726503696, 0.796397242734963]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              community    user_name  \\\n",
              "0        classicalmusic      Radaxen   \n",
              "170251  electronicmusic    headphase   \n",
              "267314      hiphopheads  thanks_bruh   \n",
              "388852       indieheads    simco1974   \n",
              "473166            Metal       sam1oq   \n",
              "\n",
              "                                               user_texts #_of_long_texts  \\\n",
              "0       I remember doing this with WC3 Dota 1 Lifestea...             339   \n",
              "170251  This Monday, June 12, r/BedStuy will become un...             305   \n",
              "267314  Whats good yâ€™all. Iâ€™m looking to make friends ...              50   \n",
              "388852  2008 or so, I was digging around at a local re...               1   \n",
              "473166  I found out that apparently I was still paying...             309   \n",
              "\n",
              "                                                   vector  \\\n",
              "0       [-0.0013457498280331492, -0.06375082582235336,...   \n",
              "170251  [0.011666242964565754, -0.035366132855415344, ...   \n",
              "267314  [0.028840450569987297, -0.06617984920740128, 0...   \n",
              "388852  [0.024371720850467682, -0.05200977995991707, 0...   \n",
              "473166  [0.024809353053569794, -0.036989957094192505, ...   \n",
              "\n",
              "                                         opn_proba  \\\n",
              "0       [[0.4633694992256616, 0.5366305007743384]]   \n",
              "170251  [[0.4260546229680149, 0.5739453770319851]]   \n",
              "267314  [[0.5274351693681876, 0.4725648306318124]]   \n",
              "388852  [[0.5114953603142274, 0.4885046396857727]]   \n",
              "473166  [[0.38509045003141096, 0.614909549968589]]   \n",
              "\n",
              "                                          ext_proba  \\\n",
              "0        [[0.4047406305005551, 0.5952593694994449]]   \n",
              "170251  [[0.6087019486538947, 0.39129805134610535]]   \n",
              "267314   [[0.5410485410530944, 0.4589514589469056]]   \n",
              "388852   [[0.4437402015227965, 0.5562597984772035]]   \n",
              "473166  [[0.5761465262055332, 0.42385347379446686]]   \n",
              "\n",
              "                                          neu_proba  \\\n",
              "0       [[0.5133525548832986, 0.48664744511670144]]   \n",
              "170251   [[0.5780140586341542, 0.4219859413658457]]   \n",
              "267314  [[0.36379346487378283, 0.6362065351262172]]   \n",
              "388852  [[0.42615630341430943, 0.5738436965856906]]   \n",
              "473166   [[0.6205980989623865, 0.3794019010376135]]   \n",
              "\n",
              "                                          agr_proba  \\\n",
              "0        [[0.2907748902422237, 0.7092251097577763]]   \n",
              "170251  [[0.24227405375973832, 0.7577259462402617]]   \n",
              "267314  [[0.37324202653229677, 0.6267579734677032]]   \n",
              "388852  [[0.37897041332216275, 0.6210295866778373]]   \n",
              "473166  [[0.21988913688937062, 0.7801108631106294]]   \n",
              "\n",
              "                                          con_proba  \n",
              "0        [[0.3720289946657592, 0.6279710053342408]]  \n",
              "170251  [[0.23508181739111556, 0.7649181826088844]]  \n",
              "267314  [[0.31871618922553135, 0.6812838107744686]]  \n",
              "388852  [[0.33153541480610726, 0.6684645851938927]]  \n",
              "473166   [[0.20360275726503696, 0.796397242734963]]  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print the first row of each community as example\n",
        "df.groupby(\"community\").head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to vectorize (new) texts & predict \n",
        "presence of each personality traits in them? <br>\n",
        "Just use the following code ðŸ‘‡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'opn': array([[0.51758315, 0.48241685]]), 'ext': array([[0.40808484, 0.59191516]]), 'neu': array([[0.41384857, 0.58615143]]), 'agr': array([[0.38006169, 0.61993831]]), 'con': array([[0.45266537, 0.54733463]])}\n"
          ]
        }
      ],
      "source": [
        "MODEL = \"intfloat/e5-large-v2\"\n",
        "\n",
        "\n",
        "def embed_and_perdict_personality_trait_presence(texts: list[str]):\n",
        "    \"\"\"Text could be a single text or a list of texts.\"\"\"\n",
        "    model = SentenceTransformer(MODEL)\n",
        "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
        "    result = {}\n",
        "    for trait, model in traits_and_models.items():\n",
        "        proba = model.predict_proba(embeddings)\n",
        "        result.update({trait: proba})\n",
        "    return result\n",
        "\n",
        "\n",
        "texts = [\"This is an example text 1\"]\n",
        "print(embed_and_perdict_personality_trait_presence(texts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final experiment:\n",
        "Predict music genre from personality probability vector <br>\n",
        "The baseline is 0.2 (because we have 5 classes). So >0.2 beats the baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['personality_vector'] = df.apply(lambda row: [float(row['proba_for_high_opn']), float(row['proba_for_high_ext']), float(row['proba_for_high_neu']), float(row['proba_for_high_agr']), float(row['proba_for_high_con'])], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=433)\n",
        "model = LogisticRegression()\n",
        "model.fit(train_df['personality_vector'].tolist(), train_df['community'])\n",
        "community_prediction = model.predict(test_df['personality_vector'].tolist())\n",
        "accuracy = accuracy_score(test_df['community'], community_prediction)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_df['community'], community_prediction, target_names=train_df['community'].unique()))\n",
        "# Print Classification Report\n",
        "classification_report = classification_report(test_df['community'], community_prediction, target_names=train_df['community'].unique(), output_dict=True)\n",
        "classification_report_df = pd.DataFrame(classification_report).transpose()\n",
        "classification_report_df = classification_report_df.drop(columns=['support'])\n",
        "\n",
        "# Set a larger figure size\n",
        "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
        "\n",
        "# Plot with a different colormap, e.g., 'viridis'\n",
        "classification_report_df.plot(kind='bar', cmap='viridis')\n",
        "\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Classification Report')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "conf_matrix = confusion_matrix(test_df['community'], community_prediction)\n",
        "print(\"Confusion Matrix:\")\n",
        "\n",
        "class_labels = ['Metal', 'Classical', 'Electronic', 'Indie', 'HipHop']\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "vals = []\n",
        "\n",
        "X = np.array(df['personality_vector'].tolist())\n",
        "y = np.array(df['community'])\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=307)\n",
        "model = LogisticRegression()\n",
        "\n",
        "accuracies = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
        "\n",
        "for i, accuracy in enumerate(accuracies, start=1):\n",
        "    print(f\"Fold {i}: Accuracy = {accuracy}\")\n",
        "\n",
        "print(f\"Average Accuracy: {np.mean(accuracies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_df['community'], community_prediction, target_names=train_df['community'].unique()))\n",
        "# Print Classification Report\n",
        "classification_report = classification_report(test_df['community'], community_prediction, target_names=train_df['community'].unique(), output_dict=True)\n",
        "classification_report_df = pd.DataFrame(classification_report).transpose()\n",
        "classification_report_df = classification_report_df.drop(columns=['support'])\n",
        "\n",
        "# Set a larger figure size\n",
        "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
        "\n",
        "# Plot with a different colormap, e.g., 'viridis'\n",
        "classification_report_df.plot(kind='bar', cmap='viridis')\n",
        "\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Classification Report')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "conf_matrix = confusion_matrix(test_df['community'], community_prediction)\n",
        "print(\"Confusion Matrix:\")\n",
        "\n",
        "class_labels = ['Metal', 'Classical', 'Electronic', 'Indie', 'HipHop']\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
