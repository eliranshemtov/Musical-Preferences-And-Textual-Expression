{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extroversion Analysis with LLM Generated Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"../analysis/llm-dataset-generation/traits-definitions.xlsx\"\n",
        "high_ext_sheet_name = \"High-EXT-GPT3.5\"\n",
        "low_ext_sheet_name = \"Low-EXT-GPT3.5\"\n",
        "\n",
        "df = pd.read_excel(file_path, sheet_name=high_ext_sheet_name)\n",
        "high_ext_texts_gpt = df.iloc[:, 0].tolist()\n",
        "\n",
        "df = pd.read_excel(file_path, sheet_name=low_ext_sheet_name)\n",
        "low_ext_texts_gpt = df.iloc[:, 0].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter unique texts\n",
        "\n",
        "Embed the dataset and apply cosine similarity to filter out \"too similar\" texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eliran/Personal/dev/Musical-Preferences-And-Textual-Expression/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "from tqdm import tqdm\n",
        "\n",
        "SIMILARITY_THRESHOLD = 0.95\n",
        "MODEL = \"intfloat/e5-large-v2\"\n",
        "\n",
        "\n",
        "def get_unique_paragraphs(texts: list[str], label: str):\n",
        "    model = SentenceTransformer(MODEL)\n",
        "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(embeddings, embeddings)\n",
        "    unique_paragraphs = []\n",
        "    unique_embeddings = []\n",
        "    for i in tqdm(range(len(texts))):\n",
        "        is_dissimilar = all(\n",
        "            similarity < SIMILARITY_THRESHOLD\n",
        "            for j, similarity in enumerate(similarities[i])\n",
        "            if j != i\n",
        "        )\n",
        "        if is_dissimilar:\n",
        "            unique_paragraphs.append(texts[i])\n",
        "            unique_embeddings.append((embeddings[i], label))\n",
        "\n",
        "    print(f\"{len(unique_paragraphs)}/{len(texts)} Unique Paragraphs.\")\n",
        "    if not unique_paragraphs:\n",
        "        print(\"No unique paragraphs found.\")\n",
        "    return unique_embeddings, unique_paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openpyxl\n",
        "\n",
        "\n",
        "def overwrite_sheet(file_path: str, sheet_name: str, texts: list[str]):\n",
        "    # workbook = openpyxl.load_workbook(file_path)\n",
        "    # if sheet_name in workbook.sheetnames:\n",
        "    #     workbook.remove(workbook[sheet_name])\n",
        "    # new_sheet = workbook.create_sheet(title=sheet_name)\n",
        "    # for i, paragraph in enumerate(texts):\n",
        "    #     new_sheet.cell(row=i + 1, column=1, value=paragraph)\n",
        "    # workbook.save(file_path)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### High Extroversion\n",
        "\n",
        "99/176 texts left\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 176/176 [00:00<00:00, 2349.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "167/176 Unique Paragraphs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "    unique_high_ext_vectors_with_labels,\n",
        "    unique_high_ext_paragraphs_gpt,\n",
        ") = get_unique_paragraphs(high_ext_texts_gpt, label=\"HIGH_EXT\")\n",
        "\n",
        "# overwrite_sheet(\n",
        "#     file_path,\n",
        "#     f\"High-EXT-GPT3.5-filtered-{SIMILARITY_THRESHOLD}\",\n",
        "#     unique_high_ext_paragraphs_gpt,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Low Extroversion\n",
        "\n",
        "102/359 texts left\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 359/359 [00:00<00:00, 1249.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "286/359 Unique Paragraphs.\n"
          ]
        }
      ],
      "source": [
        "(\n",
        "    unique_low_ext_vectors_with_labels,\n",
        "    unique_low_ext_paragraphs_gpt,\n",
        ") = get_unique_paragraphs(low_ext_texts_gpt, label=\"LOW_EXT\")\n",
        "\n",
        "# overwrite_sheet(\n",
        "#     file_path,\n",
        "#     f\"Low-EXT-GPT3.5-filtered-{SIMILARITY_THRESHOLD}\",\n",
        "#     unique_low_ext_paragraphs_gpt,\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Statistics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### High Extroversion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    167.000000\n",
              "mean      80.922156\n",
              "std       34.531284\n",
              "min       38.000000\n",
              "25%       52.000000\n",
              "50%       77.000000\n",
              "75%       98.000000\n",
              "max      199.000000\n",
              "Name: Token Count, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_unique_high_ext = pd.DataFrame(unique_high_ext_paragraphs_gpt, columns=[\"Paragraph\"])\n",
        "df_unique_high_ext[\"Token Count\"] = df_unique_high_ext[\"Paragraph\"].apply(\n",
        "    lambda x: len(x.split())\n",
        ")\n",
        "df_unique_high_ext[\"Token Count\"].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Low Extroversion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    286.000000\n",
              "mean      69.300699\n",
              "std       21.085801\n",
              "min       34.000000\n",
              "25%       53.000000\n",
              "50%       65.000000\n",
              "75%       82.000000\n",
              "max      142.000000\n",
              "Name: Token Count, dtype: float64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_unique_low_ext = pd.DataFrame(unique_low_ext_paragraphs_gpt, columns=[\"Paragraph\"])\n",
        "df_unique_low_ext[\"Token Count\"] = df_unique_low_ext[\"Paragraph\"].apply(\n",
        "    lambda x: len(x.split())\n",
        ")\n",
        "df_unique_low_ext[\"Token Count\"].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.945054945054945\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "vectors_with_labels = (\n",
        "    unique_high_ext_vectors_with_labels + unique_low_ext_vectors_with_labels\n",
        ")\n",
        "\n",
        "train_data, test_data = train_test_split(vectors_with_labels, test_size=0.2)\n",
        "train_vectors = [t[0] for t in train_data]\n",
        "train_labels = [t[1] for t in train_data]\n",
        "test_vectors = [t[0] for t in test_data]\n",
        "test_labels = [t[1] for t in test_data]\n",
        "\n",
        "\n",
        "gpt_only_model = LogisticRegression(random_state=0).fit(train_vectors, train_labels)\n",
        "print(gpt_only_model.score(test_vectors, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MyPersonality Concatenated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-Only EXT Score: 0.512\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "MODEL = \"intfloat/e5-large-v2\"\n",
        "model = SentenceTransformer(MODEL)\n",
        "myPersonality_df = pd.read_csv(\n",
        "    \"../data/myPersonality-concatenated.csv\",\n",
        "    usecols=[\"STATUS\", \"cEXT\"],\n",
        "    encoding=\"ISO-8859-1\",\n",
        ")\n",
        "value_map = {\"y\": \"HIGH_EXT\", \"n\": \"LOW_EXT\"}\n",
        "myPersonality_df[\"cEXT\"] = myPersonality_df[\"cEXT\"].map(value_map)\n",
        "myPersonality_embeddings = model.encode(\n",
        "    myPersonality_df[\"STATUS\"], convert_to_tensor=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"GPT-Only EXT Score:\",\n",
        "    gpt_only_model.score(myPersonality_embeddings, myPersonality_df[\"cEXT\"]),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MyPersonality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT-Only EXT Score: 0.5085207219925381\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "MODEL = \"intfloat/e5-large-v2\"\n",
        "model = SentenceTransformer(MODEL)\n",
        "myPersonality_df = pd.read_csv(\n",
        "    \"../data/myPersonality.csv\",\n",
        "    usecols=[\"STATUS\", \"cEXT\"],\n",
        "    encoding=\"ISO-8859-1\",\n",
        ")\n",
        "value_map = {\"y\": \"HIGH_EXT\", \"n\": \"LOW_EXT\"}\n",
        "myPersonality_df[\"cEXT\"] = myPersonality_df[\"cEXT\"].map(value_map)\n",
        "myPersonality_embeddings = model.encode(\n",
        "    myPersonality_df[\"STATUS\"], convert_to_tensor=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"GPT-Only EXT Score:\",\n",
        "    gpt_only_model.score(myPersonality_embeddings, myPersonality_df[\"cEXT\"]),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Bard's unssen dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(file_path, sheet_name=\"High-EXT-Bard-Testset\")\n",
        "high_ext_texts_bard = df.iloc[:, 0].tolist()\n",
        "high_ext_labels = [\"HIGH_EXT\" for i in high_ext_texts_bard]\n",
        "\n",
        "df = pd.read_excel(file_path, sheet_name=\"Low-EXT-Bard-Testset\")\n",
        "low_ext_texts_bard = df.iloc[:, 0].tolist()\n",
        "low_ext_labels = [\"LOW_EXT\" for i in low_ext_texts_bard]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9541284403669725"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL = \"intfloat/e5-large-v2\"\n",
        "model = SentenceTransformer(MODEL)\n",
        "bard_embeddings = model.encode(\n",
        "    high_ext_texts_bard + low_ext_texts_bard, convert_to_tensor=True\n",
        ")\n",
        "gpt_only_model.score(bard_embeddings, high_ext_labels + low_ext_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GPT & MyPerosnality Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train a logistic regression model on GPT-Generated data combined with myPersonality data\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    \"Train a logistic regression model on GPT-Generated data combined with myPersonality data\"\n",
        ")\n",
        "MODEL = \"intfloat/e5-large-v2\"\n",
        "model = SentenceTransformer(MODEL)\n",
        "myPersonality_df = pd.read_csv(\n",
        "    \"../data/myPersonality.csv\", usecols=[\"STATUS\", \"cEXT\"], encoding=\"ISO-8859-1\"\n",
        ")\n",
        "value_map = {\"y\": \"HIGH_EXT\", \"n\": \"LOW_EXT\"}\n",
        "myPersonality_df[\"cEXT\"] = myPersonality_df[\"cEXT\"].map(value_map)\n",
        "# myPersonality_embeddings = model.encode(\n",
        "#     myPersonality_df[\"STATUS\"], convert_to_tensor=True\n",
        "# )\n",
        "my_personality_vectors_with_labels = list(\n",
        "    zip(myPersonality_embeddings.tolist(), myPersonality_df[\"cEXT\"])\n",
        ")\n",
        "\n",
        "vectors_with_labels = (\n",
        "    unique_high_ext_vectors_with_labels\n",
        "    + unique_low_ext_vectors_with_labels\n",
        "    + my_personality_vectors_with_labels\n",
        ")\n",
        "\n",
        "train_vectors = [t[0] for t in vectors_with_labels]\n",
        "train_labels = [t[1] for t in vectors_with_labels]\n",
        "\n",
        "gpt_and_myPersonality_model = LogisticRegression(random_state=0).fit(\n",
        "    train_vectors, train_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8486238532110092"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpt_and_myPersonality_model.score(bard_embeddings, high_ext_labels + low_ext_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"../models/gpt_and_myPersonality_ext_95.pkl\", \"wb\") as file:\n",
        "    pickle.dump(gpt_and_myPersonality_model, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "high_bard_embeddings = model.encode(high_ext_texts_bard, convert_to_tensor=True)\n",
        "low_bard_embeddings = model.encode(low_ext_texts_bard, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "high_ext_predictions = gpt_only_model.predict(high_bard_embeddings)\n",
        "low_ext_predictions = gpt_only_model.predict(low_bard_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eliran/Personal/dev/Musical-Preferences-And-Textual-Expression/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1.0, 0.908256880733945, '99/109')"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# HIGHs\n",
        "true_labels = [\"HIGH_EXT\"] * len(high_ext_texts_bard)\n",
        "precision = precision_score(true_labels, high_ext_predictions, average='weighted')\n",
        "recall = recall_score(true_labels, high_ext_predictions, average='weighted')\n",
        "correct_predictions = sum([1 for pred in high_ext_predictions if pred == \"HIGH_EXT\"])\n",
        "\n",
        "precision, recall, f\"{correct_predictions}/{len(high_ext_texts_bard)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1.0, 1.0, '109/109')"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# LOWs\n",
        "true_labels = [\"LOW_EXT\"] * len(low_ext_predictions)\n",
        "precision = precision_score(true_labels, low_ext_predictions, average='weighted')\n",
        "recall = recall_score(true_labels, low_ext_predictions, average='weighted')\n",
        "correct_predictions = sum([1 for pred in low_ext_predictions if pred == \"LOW_EXT\"])\n",
        "\n",
        "precision, recall, f\"{correct_predictions}/{len(low_ext_predictions)}\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
